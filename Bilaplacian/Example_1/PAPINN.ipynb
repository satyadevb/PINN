{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "from math import exp, sqrt, pi\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset,RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "eps = 1\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batchflag = True\n",
    "batchsize = 128\n",
    "\n",
    "start = 0.\n",
    "end = 1.\n",
    "x = np.linspace(start,end,100 )\n",
    "y = np.linspace(start,end,100)\n",
    "x, y = np.meshgrid(x, y)\n",
    "x = np.reshape(x, (np.size(x[:]),1))\n",
    "y = np.reshape(y, (np.size(y[:]),1))\n",
    "\n",
    "def actual_soln(eps):\n",
    "    return 256*(x**2 + eps**2 * (1 - np.exp(-x/eps))**2 )*((x-1)**2)*(y**2)*((y-1)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(soln,soln_name):\n",
    "    x = np.linspace(start,end,100);y = np.linspace(start,end,100)\n",
    "    x,y = np.meshgrid(x,y)\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.plot_surface(x,y,soln.reshape(100,100))\n",
    "    plt.title(soln_name)\n",
    "    plt.show()\n",
    "\n",
    "def plot_graphs(soln1,soln2,soln_name):\n",
    "    x = np.linspace(start,end,100);y = np.linspace(start,end,100)\n",
    "    x,y = np.meshgrid(x,y)\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.plot_surface(x,y,soln1.reshape(100,100))\n",
    "    plt.title(soln_name)\n",
    "    plt.show()\n",
    "\n",
    "class Swish(nn.Module):\n",
    "\tdef __init__(self, inplace=True):\n",
    "\t\tsuper(Swish, self).__init__()\n",
    "\t\tself.inplace = inplace\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tif self.inplace:\n",
    "\t\t\tx.mul_(torch.sigmoid(x))\n",
    "\t\t\treturn x\n",
    "\t\telse:\n",
    "\t\t\treturn x * torch.sigmoid(x)\n",
    "\t\n",
    "\n",
    "class FBPINN(nn.Module):\n",
    "\thid_dim = 128\n",
    "\tinput_dim = 2 \n",
    "\tdef __init__(self):\n",
    "\t\tsuper(FBPINN, self).__init__()\n",
    "\t\tself.tanh = nn.Tanh()\n",
    "\t\tself.lin0 = nn.Linear(self.input_dim,self.hid_dim)\n",
    "\t\tself.lin = nn.Linear(self.hid_dim,self.hid_dim)\n",
    "\t\tself.lin1 = nn.Linear(self.hid_dim,1)\n",
    "\t\tself.swish = Swish()\n",
    "\n",
    "\n",
    "\tdef forward(self,x):\t\t\n",
    "\t\ttanh1 = self.tanh(x)\n",
    "\t\ttanh2 = self.tanh(1 - x)\n",
    "\t\ttanh11 = (tanh1[:,0].unsqueeze(1))*(tanh1[:,1].unsqueeze(1))*(tanh1[:,0].unsqueeze(1))*(tanh1[:,1].unsqueeze(1))\n",
    "\t\ttanh22 = (tanh2[:,0].unsqueeze(1))*(tanh2[:,1].unsqueeze(1))*(tanh2[:,0].unsqueeze(1))*(tanh2[:,1].unsqueeze(1))\n",
    "\t\tx = self.lin0(x)\n",
    "\t\tx = self.swish(x)\n",
    "\t\tx = self.lin(x)\n",
    "\t\tx = self.swish(x)\n",
    "\t\tx = self.lin(x)\n",
    "\t\tx = self.swish(x)\n",
    "\t\tx = self.lin(x)\n",
    "\t\tx = self.swish(x)\n",
    "\t\tx = self.lin1(x)\n",
    "\t\tout = x*tanh11*tanh22\n",
    "\t\treturn out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(device,net,x,y,eps,learning_rate,epochs,batch_flag,batch_size):\n",
    "\n",
    "\txnet = torch.Tensor(x)\n",
    "\tynet = torch.Tensor(y) \n",
    "\t\n",
    "\tif(batch_flag):\n",
    "\t\tdataset = TensorDataset(xnet,ynet)\n",
    "\t\tdataloader = DataLoader(dataset, batch_size=batch_size,shuffle=True,num_workers = 0,drop_last = True )\n",
    "\t\n",
    "\toptimizer = optim.Adam(net.parameters(), lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "\n",
    "\tdef Loss_criterion(xnet,ynet):\n",
    "\t\txnet.requires_grad = True\n",
    "\t\tynet.requires_grad = True\n",
    "\t\tpoints = torch.cat((xnet,ynet),1) \n",
    "\t\tU = net(points)\n",
    "\t\tU = U.view(len(U),-1)\n",
    "\t\t\n",
    "\t\tsoln = 256*(xnet**2 + eps**2 * (1 - torch.exp(-xnet/eps))**2 )*((xnet-1)**2)*(ynet**2)*((ynet-1)**2)\n",
    "\t\t\n",
    "\t\tsoln_x = torch.autograd.grad(soln,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_xx = torch.autograd.grad(soln_x,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_xxx = torch.autograd.grad(soln_xx,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_xxxx = torch.autograd.grad(soln_xxx,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_y = torch.autograd.grad(soln,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_yy = torch.autograd.grad(soln_y,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_yyy = torch.autograd.grad(soln_yy,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_yyyy = torch.autograd.grad(soln_yyy,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_xxy = torch.autograd.grad(soln_xx,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tsoln_xxyy = torch.autograd.grad(soln_xxy,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\t\n",
    "\t\tf = (eps**2)*(soln_xxxx + soln_yyyy + 2*soln_xxyy) - (soln_xx + soln_yy)\n",
    "\t\t\n",
    "\t\tU_x = torch.autograd.grad(U,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_xx = torch.autograd.grad(U_x,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_xxx = torch.autograd.grad(U_xx,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_xxxx = torch.autograd.grad(U_xxx,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_y = torch.autograd.grad(U,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_yy = torch.autograd.grad(U_y,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_yyy = torch.autograd.grad(U_yy,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_yyyy = torch.autograd.grad(U_yyy,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_xxy = torch.autograd.grad(U_xx,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_xxyy = torch.autograd.grad(U_xxy,ynet,grad_outputs=torch.ones_like(ynet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tloss1 = (eps**2)*(U_xxxx + U_yyyy + 2*U_xxyy) - (U_xx + U_yy) - f \n",
    "\t\t\n",
    "\t\treturn nn.MSELoss()(loss1,torch.zeros_like(loss1)) \n",
    "\n",
    "\tlosses = []\n",
    "\ttic = time.time()\n",
    "\n",
    "\tif(batch_flag):\n",
    "\t\tfor epoch in range(epochs):\n",
    "\t\t\tif epoch == 30:\n",
    "\t\t\t\tlearning_rate = 0.00001\n",
    "\t\t\t\tnew_optimizer = optim.Adam(net.parameters(), lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "\t\t\t\toptimizer = new_optimizer\n",
    "\t\t\tfor batch_idx, (x_in,y_in) in enumerate(dataloader):\n",
    "\n",
    "\t\t\t\tnet.zero_grad()\n",
    "\t\t\t\tloss = Loss_criterion(x_in,y_in)\n",
    "\t\t\t\tloss.backward()\n",
    "\n",
    "\t\t\t\toptimizer.step() \n",
    "\t\t\t\tif batch_idx % 20 ==0:\n",
    "\t\t\t\t\tprint('Train Epoch: {} \\tLoss: {:.20f}'.format(epoch, loss.item()))\n",
    "\n",
    "\t\t\tpoints = torch.cat((xnet,ynet),1)\n",
    "\t\t\tU = net(points)\n",
    "\t\t\tz = U.detach().numpy()\n",
    "\t\t\tactual_loss = np.square(actual_soln(eps) - z).mean()\n",
    "\t\t\tprint('\\nAfter Epoch {}, \\t Actual solution loss: {:.20f}\\n'.format(\n",
    "\t\t\t\tepoch, actual_loss))\n",
    "\t\t\tif epoch % 1 == 0:\n",
    "\t\t\t\tplot_graph(z,'Predicted solution')\n",
    "\t\t\t\n",
    "\t\t\tlosses.append([loss.item(),actual_loss])\n",
    "\n",
    "\telse:\n",
    "\t\tfor epoch in range(epochs):\n",
    "\t\t\tif epoch == 50:\n",
    "\t\t\t\tlearning_rate = 0.00001\n",
    "\t\t\t\tnew_optimizer = optim.Adam(net.parameters(), lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "\t\t\t\toptimizer = new_optimizer\n",
    "\t\t\n",
    "\t\t\tnet.zero_grad()\n",
    "\t\t\tloss = Loss_criterion(xnet,ynet)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\t\n",
    "\t\t\toptimizer.step() \n",
    "\t\t\tpoints = torch.cat((xnet,ynet),1)\n",
    "\t\t\tU = net(points)\n",
    "\t\t\tz = U.detach().numpy()\n",
    "\t\t\tactual_loss = np.square(actual_soln(eps) - z).mean()\n",
    "\t\t\tprint('\\nAfter Epoch {}, \\t Actual solution loss: {:.20f}\\n'.format(\n",
    "\t\t\t\tepoch, actual_loss))\n",
    "\t\t\tif epoch % 5 == 0:\n",
    "\t\t\t\tplot_graph(z,'Predicted solution')\n",
    "\t\t\t\n",
    "\t\t\tlosses.append([loss.item(),actual_loss])\n",
    "\n",
    "\ttoc = time.time()\n",
    "\telapseTime = toc - tic\n",
    "\tprint (\"Time elapsed = \", elapseTime)\n",
    "\n",
    "\tnet_in = torch.cat((xnet,ynet),1)\n",
    "\toutput = net(net_in)  \n",
    "\t\n",
    "\treturn output,net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(actual_soln(1),'Actual solution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FBPINN()#.to(device)\n",
    "\t\n",
    "def init_normal(m):\n",
    "\tif type(m) == nn.Linear:\n",
    "\t\tnn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "net.apply(init_normal)\n",
    "\n",
    "for eps in [1,0.5,0.1,0.05,0.01,0.005,0.001]:\n",
    "\tprint('\\n\\n{}\\n\\n'.format(eps))\n",
    "\toutput,net = train(device,net,x,y,eps,learning_rate,epochs,batchflag,batchsize)\n",
    "\tplot_graph(output.detach().numpy(),\"After one round\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
