{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pdb\n",
    "import math\n",
    "from torch.utils.data import DataLoader, TensorDataset,RandomSampler\n",
    "from math import exp, sqrt,pi\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt, numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 \tLoss: 7.5702314377 \t Loss BC 1.765891\n",
      "Train Epoch: 10 \tLoss: 6.1825733185 \t Loss BC 1.571737\n",
      "Train Epoch: 20 \tLoss: 5.0387949944 \t Loss BC 1.410690\n",
      "Train Epoch: 30 \tLoss: 4.1195440292 \t Loss BC 1.278707\n",
      "Train Epoch: 40 \tLoss: 3.3917131424 \t Loss BC 1.170317\n",
      "Train Epoch: 50 \tLoss: 2.8187460899 \t Loss BC 1.079923\n",
      "Train Epoch: 60 \tLoss: 2.3673033714 \t Loss BC 1.002657\n",
      "Train Epoch: 70 \tLoss: 2.0098509789 \t Loss BC 0.934665\n",
      "Train Epoch: 80 \tLoss: 1.7247533798 \t Loss BC 0.873084\n",
      "Train Epoch: 90 \tLoss: 1.4953708649 \t Loss BC 0.815898\n",
      "Train Epoch: 100 \tLoss: 1.3089921474 \t Loss BC 0.761759\n",
      "Train Epoch: 110 \tLoss: 1.1558911800 \t Loss BC 0.709824\n",
      "Train Epoch: 120 \tLoss: 1.0286021233 \t Loss BC 0.659624\n",
      "Train Epoch: 130 \tLoss: 0.9213781357 \t Loss BC 0.610951\n",
      "Train Epoch: 140 \tLoss: 0.8297936916 \t Loss BC 0.563766\n",
      "Train Epoch: 150 \tLoss: 0.7504483461 \t Loss BC 0.518142\n",
      "Train Epoch: 160 \tLoss: 0.6807453036 \t Loss BC 0.474207\n",
      "Train Epoch: 170 \tLoss: 0.6187198758 \t Loss BC 0.432116\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train(device,x,y,xb,yb,ub,learning_rate,epochs):\n",
    "\tx = torch.Tensor(x).to(device)\n",
    "\ty = torch.Tensor(y).to(device) \n",
    "\txb1,xb2,xb3,xb4 = xb\n",
    "\tyb1,yb2,yb3,yb4 = yb\n",
    "\tub1,ub2,ub3,ub4 = ub\n",
    "\txb1 = torch.Tensor(xb1).to(device) \t\n",
    "\tyb1 = torch.Tensor(yb1).to(device) \n",
    "\tub1 = torch.Tensor(ub1).to(device)\n",
    "\txb2 = torch.Tensor(xb2).to(device) \t\n",
    "\tyb2 = torch.Tensor(yb2).to(device) \n",
    "\tub2 = torch.Tensor(ub2).to(device)\n",
    "\txb3 = torch.Tensor(xb3).to(device) \t\n",
    "\tyb3 = torch.Tensor(yb3).to(device) \n",
    "\tub3 = torch.Tensor(ub3).to(device)\n",
    "\txb4 = torch.Tensor(xb4).to(device) \t\n",
    "\tyb4 = torch.Tensor(yb4).to(device) \n",
    "\tub4 = torch.Tensor(ub4).to(device)\n",
    "\n",
    "\th_n = 128\n",
    "\tinput_n = 2  \n",
    "\tclass Swish(nn.Module):\n",
    "\t\tdef __init__(self, inplace=True):\n",
    "\t\t\tsuper(Swish, self).__init__()\n",
    "\t\t\tself.inplace = inplace\n",
    "\n",
    "\t\tdef forward(self, x):\n",
    "\t\t\tif self.inplace:\n",
    "\t\t\t\tx.mul_(torch.sigmoid(x))\n",
    "\t\t\t\treturn x\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn x * torch.sigmoid(x)\n",
    "\t\n",
    "\n",
    "\tclass Net(nn.Module):\n",
    "\t\tdef __init__(self):\n",
    "\t\t\tsuper(Net, self).__init__()\n",
    "\t\t\tself.main = nn.Sequential(\n",
    "\t\t\t\tnn.Linear(input_n,h_n),\n",
    "\t\t\t\tSwish(),\n",
    "\t\t\t\tnn.Linear(h_n,h_n),\n",
    "\t\t\t\tSwish(),\n",
    "\t\t\t\tnn.Linear(h_n,h_n),\n",
    "\t\t\t\tSwish(),\n",
    "\t\t\t\tnn.Linear(h_n,h_n),\n",
    "\t\t\t\t#Swish(),\n",
    "\t\t\t\t#nn.Linear(h_n,h_n),\n",
    "\t\t\t\tSwish(),\n",
    "\t\t\t\tnn.Linear(h_n,h_n),\n",
    "\t\t\t\tSwish(),\n",
    "\t\t\t\tnn.Linear(h_n,h_n),\n",
    "        \t\tSwish(),\n",
    "\t\t\t\tnn.Linear(h_n,1),\n",
    "\t\t\t)\t\t\n",
    "\t\tdef forward(self,x):\t\t\n",
    "\t\t\toutput = self.main(x)\n",
    "\t\t\treturn  output\n",
    "\n",
    "\t\n",
    "\tnet = Net().to(device)\n",
    "\t\n",
    "\tdef init_normal(m):\n",
    "\t\tif type(m) == nn.Linear:\n",
    "\t\t\tnn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "\tnet.apply(init_normal)\n",
    "\n",
    "\toptimizer2 = optim.Adam(net.parameters(), lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "\n",
    "\tdef Loss_criterion(x,y):\n",
    "\t\tx.requires_grad = True\n",
    "\t\ty.requires_grad = True\n",
    "\t\tpoints = torch.cat((x,y),1) \n",
    "\t\tU = net(points)\n",
    "\t\tU = U.view(len(U),-1)\n",
    "\t\tU_x = torch.autograd.grad(U,x,grad_outputs=torch.ones_like(x),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_xx = torch.autograd.grad(U_x,x,grad_outputs=torch.ones_like(x),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_y = torch.autograd.grad(U,y,grad_outputs=torch.ones_like(y),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_yy = torch.autograd.grad(U_y,y,grad_outputs=torch.ones_like(y),create_graph = True,only_inputs=True)[0]\n",
    "\t\tloss1 = U_xx + U_yy\n",
    "\t\treturn nn.MSELoss()(loss1,torch.zeros_like(loss1)) \n",
    "\n",
    "\tdef Loss_BC(xb1,xb2,xb3,xb4,yb1,yb2,yb3,ub1,ub2,ub3,ub4):\n",
    "\t\t\n",
    "\t\tloss_bc = 0\n",
    "\n",
    "\t\tnet1 = torch.cat((xb1, yb1), 1)\n",
    "\t\tout1 = net(net1)\n",
    "\t\tub1_pred = out1.view(len(out1), -1)\n",
    "\t\tloss_f = nn.MSELoss()\n",
    "\t\tloss_bc += loss_f(ub1_pred,ub1)\n",
    "\t\t\n",
    "\t\tnet2 = torch.cat((xb2, yb2), 1)\n",
    "\t\tout2 = net(net2)\n",
    "\t\tub2_pred = out2.view(len(out2), -1)\n",
    "\t\tloss_f = nn.MSELoss()\n",
    "\t\tloss_bc += loss_f(ub2_pred,ub2)\n",
    "\n",
    "\t\tnet3 = torch.cat((xb3, yb3), 1)\n",
    "\t\tout3 = net(net3)\n",
    "\t\tub3_pred = out3.view(len(out3), -1)\n",
    "\t\tloss_f = nn.MSELoss()\n",
    "\t\tloss_bc += loss_f(ub3_pred,ub3)\n",
    "\n",
    "\t\tnet4 = torch.cat((xb4, yb4), 1)\n",
    "\t\tout4 = net(net4)\n",
    "\t\tub4_pred = out4.view(len(out4), -1)\n",
    "\t\tloss_f = nn.MSELoss()\n",
    "\t\tloss_bc += loss_f(ub4_pred,ub4)\n",
    "\n",
    "\t\treturn loss_bc\n",
    "\n",
    "\n",
    "\t\n",
    "\tlosses = []\n",
    "\ttic = time.time()\n",
    "\n",
    "\n",
    "\tfor epoch in range(epochs):\n",
    "\t\tnet.zero_grad()\n",
    "\t\tloss_eqn = Loss_criterion(x,y)\n",
    "\t\tloss_bc = Loss_BC(xb1,xb2,xb3,xb4,yb1,yb2,yb3,ub1,ub2,ub3,ub4)\n",
    "\t\tloss = loss_eqn + loss_bc\n",
    "\t\tloss.backward()\n",
    "\t\t\t\n",
    "\t\toptimizer2.step() \n",
    "\t\tif epoch % 10 ==0:\n",
    "\t\t\tprint('Train Epoch: {} \\tLoss: {:.10f} \\t Loss BC {:.6f}'.format(\n",
    "\t\t\t\tepoch, loss.item(),loss_bc.item()))\n",
    "\t\t\tlosses.append(loss.item())\n",
    "\n",
    "\ttoc = time.time()\n",
    "\telapseTime = toc - tic\n",
    "\tprint (\"elapse time in parallel = \", elapseTime)\n",
    "\n",
    "\tnet_in = torch.cat((x,y),1)\n",
    "\toutput = net(net_in)  #evaluate model\n",
    "\t\n",
    "\treturn output \n",
    "\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "batchsize = 128 \n",
    "learning_rate = 1e-5   \n",
    "\n",
    "epochs = 500 \n",
    "\n",
    "n = 100 \n",
    "\n",
    "x = np.linspace(-1.,1.,100 )\n",
    "y = np.linspace(-1.,1.,100)\n",
    "x, y = np.meshgrid(x, y)\n",
    "x = np.reshape(x, (np.size(x[:]),1))\n",
    "y = np.reshape(y, (np.size(y[:]),1))\n",
    "\n",
    "xb1 = np.linspace(-1.,1., 100 )\n",
    "yb1 = np.linspace(-1.,-1., 100 ) \n",
    "cb1 = xb1*yb1\n",
    "xb1 = xb1.reshape(-1, 1)\n",
    "yb1 = yb1.reshape(-1, 1)\n",
    "cb1 = cb1.reshape(-1, 1)\n",
    "\n",
    "xb2 = np.linspace(-1.,1., 100 )\n",
    "yb2 = np.linspace(1.,1., 100 ) \n",
    "cb2 = xb2*yb2\n",
    "xb2 = xb2.reshape(-1, 1)\n",
    "yb2 = yb2.reshape(-1, 1)\n",
    "cb2 = cb2.reshape(-1, 1)\n",
    "\n",
    "xb3 = np.linspace(1.,1., 100 )\n",
    "yb3 = np.linspace(-1.,1., 100 ) \n",
    "cb3 = xb3*yb3\n",
    "xb3 = xb3.reshape(-1, 1)\n",
    "yb3 = yb3.reshape(-1, 1)\n",
    "cb3 = cb3.reshape(-1, 1)\n",
    "\n",
    "xb4 = np.linspace(-1.,-1., 100 )\n",
    "yb4 = np.linspace(-1.,1., 100 ) \n",
    "cb4 = xb4*yb4\n",
    "xb4 = xb4.reshape(-1, 1)\n",
    "yb4 = yb4.reshape(-1, 1)\n",
    "cb4 = cb4.reshape(-1, 1)\n",
    "\n",
    "xb = [xb1,xb2,xb3,xb4]\n",
    "yb = [yb1,yb2,yb3,yb4]\n",
    "cb = [cb1,cb2,cb3,cb4]\n",
    "\n",
    "output = train(device,x,y,xb,yb,cb,learning_rate,epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = output.detach().numpy()\n",
    "x = np.linspace(-1.,1.,100 )\n",
    "y = np.linspace(-1.,1.,100)\n",
    "x, y = np.meshgrid(x, y)\n",
    "x = np.reshape(x, (np.size(x[:]),1))\n",
    "y = np.reshape(y, (np.size(y[:]),1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(x,y,z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
