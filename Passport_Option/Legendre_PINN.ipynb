{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset,RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "#n = 100 \n",
    "K = 1\n",
    "\n",
    "r = 0.05;gamma = 0.05\n",
    "sigma = 0.3;T = 1\n",
    "\n",
    "x_start = -np.exp(4*sigma*np.sqrt(T));x_end = np.exp(4*sigma*np.sqrt(T))\n",
    "t_start = 0.;t_end = 1.\n",
    "\n",
    "x = np.linspace(x_start,x_end,100 )\n",
    "t = np.linspace(t_start,t_end,100 )\n",
    "x, t = np.meshgrid(x, t)\n",
    "x = np.reshape(x, (np.size(x[:]),1))\n",
    "t = np.reshape(t, (np.size(t[:]),1))\n",
    "\n",
    "x_left = np.linspace(x_start,x_start, 100 )\n",
    "t_left = np.linspace(t_start,t_end, 100 ) \n",
    "v_left = np.zeros(100)\n",
    "x_left = x_left.reshape(-1, 1)\n",
    "t_left = t_left.reshape(-1, 1)\n",
    "v_left = v_left.reshape(-1, 1)\n",
    "\n",
    "x_up = np.linspace(x_start,x_end, 100 )\n",
    "t_up = np.linspace(t_end,t_end, 100 ) \n",
    "v_up = (x_up > 0)*x_up\n",
    "x_up = x_up.reshape(-1, 1)\n",
    "t_up = t_up.reshape(-1, 1)\n",
    "v_up = v_up.reshape(-1, 1)\n",
    "\n",
    "x_right = np.linspace(x_end,x_end, 100 )\n",
    "t_right = np.linspace(t_start,t_end, 100 ) \n",
    "v_right = np.exp(-r*(T-t_right))\n",
    "x_right = x_right.reshape(-1, 1)\n",
    "t_right = t_right.reshape(-1, 1)\n",
    "v_right = v_right.reshape(-1, 1)\n",
    "\n",
    "\n",
    "x_bound = [x_left,x_up,x_right]\n",
    "t_bound = [t_left,t_up,t_right]\n",
    "v_bound = [v_left,v_up,v_right]\n",
    "\n",
    "\n",
    "batchsize = 128 \n",
    "batch_flag = True\n",
    "\n",
    "d = -np.log(1 + np.abs(x))/(sigma*np.sqrt(T-t)) + (sigma/2)*np.sqrt(T-t) \n",
    "\n",
    "for i in range(9900,10000):\n",
    "    d[i] = -100000\n",
    "\n",
    "actual_soln = np.exp(-gamma* (T - t))*((x > 0)*(x) + (d*sigma*np.sqrt(T - t) + 1)* norm.cdf(d)/2 - (np.abs(x) + 1)* norm.cdf(d - np.sqrt(T-t))/2  + (sigma*np.sqrt(T - t))* norm.pdf(d))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(soln,soln_name):\n",
    "    x = np.linspace(x_start,x_end,100);t = np.linspace(t_start,t_end,100)\n",
    "    x,t = np.meshgrid(x,t)\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.plot_surface(x,t,soln.reshape(100,100))\n",
    "    plt.title(soln_name)\n",
    "    plt.show()\n",
    "\n",
    "def legendre_coeffs(num):\n",
    "\t\tlis = [np.array([1]),np.array([0,1])]\n",
    "\t\tfor n in range(1,num-1):\n",
    "\t\t\txl1 = np.concatenate((np.array([0]),lis[n]),axis = 0)\n",
    "\t\t\tl0 = np.concatenate((lis[n-1],np.array([0,0])),axis = 0)\n",
    "\t\t\tl = ((2*n + 1)*xl1 - n*l0)/(n + 1)\n",
    "\t\t\tlis.append(l)\n",
    "\t\tfor n in range(num):\n",
    "\t\t\tlis[n] = np.concatenate((lis[n],np.array([0]*(num-1-n))),axis = 0)\n",
    "\t\treturn lis\n",
    "\n",
    "def poly(coeffs,x):\n",
    "\tsum = torch.zeros_like(x)\n",
    "\tfor i,coeff in enumerate(coeffs):\n",
    "\t\tsum = sum + coeff*(x**i)\n",
    "\treturn sum\n",
    "\t\n",
    "class Legendre_PINN(nn.Module):\n",
    "\tdef __init__(self,basis_num):\n",
    "\t\tsuper(Legendre_PINN,self).__init__()\n",
    "\t\tself.tanh = nn.Tanh()\n",
    "\t\tself.basis_num = basis_num\n",
    "\t\tself.main = nn.Sequential(\n",
    "\t\t\t#nn.Linear(2*basis_num,2*basis_num),\n",
    "\t\t\tnn.Linear(2*basis_num,1))\t\t\n",
    "\tdef forward(self,input):\n",
    "\t\tcoeffs = legendre_coeffs(self.basis_num)\n",
    "\t\tx = input[:,0]\n",
    "\t\tt = input[:,1]\n",
    "\t\tnetin = torch.Tensor([])\n",
    "\t\tfor i in range(self.basis_num):\n",
    "\t\t\tnetin = torch.cat((netin,poly(coeffs[i],x.view(-1,1))),1)\n",
    "\t\tfor i in range(self.basis_num):\n",
    "\t\t\tnetin = torch.cat((netin,poly(coeffs[i],t.view(-1,1))),1)\n",
    "\t\tnetout = self.main(netin)\n",
    "\t\treturn netout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(device,x,t,x_bound,t_bound,v_bound,learning_rate,basis_num,epochs,batch_flag,batch_size):\n",
    "\n",
    "\txnet = torch.Tensor(x).to(device)\n",
    "\ttnet = torch.Tensor(t).to(device) \n",
    "\tx_left,x_up,x_right = x_bound\n",
    "\tt_left,t_up,t_right = t_bound\n",
    "\tV_left,V_up,V_right = v_bound\n",
    "\n",
    "\tx_left = torch.Tensor(x_left).to(device) \t\n",
    "\tt_left = torch.Tensor(t_left).to(device) \t\n",
    "\tV_left = torch.Tensor(V_left).to(device)\n",
    "\tx_up = torch.Tensor(x_up).to(device) \t\n",
    "\tt_up = torch.Tensor(t_up).to(device) \t\n",
    "\tV_up = torch.Tensor(V_up).to(device)\n",
    "\tx_right = torch.Tensor(x_right).to(device) \t\n",
    "\tt_right = torch.Tensor(t_right).to(device) \t\n",
    "\tV_right = torch.Tensor(V_right).to(device)\n",
    "\n",
    "\tif(batch_flag):\n",
    "\t\tdataset = TensorDataset(xnet,tnet)\n",
    "\t\tdataloader = DataLoader(dataset, batch_size=batch_size,shuffle=True,num_workers = 0,drop_last = True )\n",
    "\t\tprint(len(dataloader))\n",
    "\n",
    "\n",
    "\tnet = Legendre_PINN(basis_num).to(device)\n",
    "\t\n",
    "\tdef init_normal(m):\n",
    "\t\tif type(m) == nn.Linear:\n",
    "\t\t\tnn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "\tnet.apply(init_normal)\n",
    "\n",
    "\toptimizer = optim.Adam(net.parameters(), lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "\n",
    "\tdef Loss_criterion(xnet,tnet):\n",
    "\t\txnet.requires_grad = True\n",
    "\t\ttnet.requires_grad = True\n",
    "\t\tpoints = torch.cat((xnet,tnet),1) \n",
    "\t\tV = net(points)\n",
    "\t\tV = V.view(len(V),-1)\n",
    "\t\tV_x = torch.autograd.grad(V,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tV_xx = torch.autograd.grad(V_x,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tV_t = torch.autograd.grad(V,tnet,grad_outputs=torch.ones_like(tnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tu = ((r - gamma)*V_x - xnet*(sigma**2)*V_xx > 0).long()\n",
    "\t\tloss = V_t + (u - xnet)*(r - gamma)*V_x + ((u - xnet)**2)*(sigma**2)*V_xx/2 - gamma * V\n",
    "\t\treturn nn.MSELoss()(loss,torch.zeros_like(loss)) \n",
    "\n",
    "\tdef Loss_BC(x_left,t_left,V_left,x_up,t_up,V_up,x_right,t_right,V_right):\n",
    "\t\tx_right.requires_grad = True\n",
    "\t\tleft = torch.cat((x_left, t_left), 1)\n",
    "\t\tout = net(left)\n",
    "\t\tV_left_pred = out.view(len(out), -1)\n",
    "\t\tloss_f = nn.MSELoss()\n",
    "\t\tloss_left = loss_f(V_left_pred,V_left)\n",
    "\n",
    "\t\tup = torch.cat((x_up, t_up), 1)\n",
    "\t\tout = net(up)\n",
    "\t\tV_up_pred = out.view(len(out), -1)\n",
    "\t\tloss_f = nn.MSELoss()\n",
    "\t\tloss_up = loss_f(V_up_pred,V_up)\n",
    "\t\t\n",
    "\t\tright = torch.cat((x_right, t_right), 1)\n",
    "\t\tout = net(right)\n",
    "\t\tV_right_pred = out.view(len(out), -1)\n",
    "\t\tVx_right_pred = torch.autograd.grad(V_right_pred,x_right,grad_outputs=torch.ones_like(x_right),create_graph = True,only_inputs=True)[0]\n",
    "\t\tloss_f = nn.MSELoss()\n",
    "\t\tloss_right = loss_f(Vx_right_pred,V_right)\n",
    "\n",
    "\t\tloss_bc = loss_right + loss_left + loss_up\n",
    "\t\treturn loss_bc,loss_right,loss_left,loss_up\n",
    "\n",
    "\n",
    "\tlosses = []\n",
    "\ttic = time.time()\n",
    "\n",
    "\tif(batch_flag):\n",
    "\t\tfor epoch in range(epochs):\n",
    "\t\t\tif epoch == 250:\n",
    "\t\t\t\tlearning_rate = 0.00001\n",
    "\t\t\t\tnew_optimizer = optim.Adam(net.parameters(), lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "\t\t\t\toptimizer = new_optimizer\n",
    "\t\t\tfor batch_idx, (x_in,t_in) in enumerate(dataloader):\n",
    "\n",
    "\t\t\t\tnet.zero_grad()\n",
    "\t\t\t\tloss_eqn = Loss_criterion(x_in,t_in)\n",
    "\t\t\t\tloss_bc,loss_right,loss_left,loss_up = Loss_BC(x_left,t_left,V_left,x_up,t_up,V_up,x_right,t_right,V_right)\n",
    "\t\t\t\tloss = loss_eqn + loss_bc\n",
    "\t\t\t\tloss.backward()\n",
    "\n",
    "\t\t\t\toptimizer.step() \n",
    "\t\t\t\tif batch_idx % 20 ==0:\n",
    "\t\t\t\t\tprint('\\nTrain Epoch: {} \\tLoss: {:.10f}\\tEquation Loss: {:.10f} \\t BC Loss {:.6f}\\nRight_boundary loss {:.10f}\\tLeft_boundary loss {:.10f}\\tUp_boundary loss {:.10f}\\n'.format(epoch, loss.item(),loss_eqn.item(),loss_bc.item(),loss_right.item(),loss_left.item(),loss_up.item()))\n",
    "\n",
    "\t\t\t\t\t\n",
    "\t\t\tpoints = torch.cat((xnet,tnet),1)\n",
    "\t\t\tU = net(points)\n",
    "\t\t\tz = U.detach().numpy()\n",
    "\t\t\tactual_loss = np.square(actual_soln - z).mean()\n",
    "\t\t\tprint('\\nAfter Epoch {}, \\t Actual solution loss: {:.10f}\\n'.format(\n",
    "\t\t\t\tepoch, actual_loss))\n",
    "\n",
    "\t\t\tif epoch % 1 == 0:\n",
    "\t\t\t\tplot_graph(z,'Predicted solution')\n",
    "\t\t\t#if epoch % 50 == 0:\n",
    "\t\t\t#\tprint('Train Epoch: {} \\tLoss: {:.10f}\\tEquation Loss: {:.10f} \\t BC Loss {:.6f}'.format(epoch, loss.item(),loss_eqn.item(),loss_bc.item()))\n",
    "\t\t\t#losses.append(loss.item())\n",
    "\t\t\t\t\t\n",
    "\telse:\n",
    "\t\tfor epoch in range(epochs):\n",
    "\t\t\tif epoch == 2000:\n",
    "\t\t\t\tlearning_rate = 0.00001\n",
    "\t\t\t\tnew_optimizer = optim.Adam(net.parameters(), lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "\t\t\t\toptimizer = new_optimizer\n",
    "\t\t\tnet.zero_grad()\n",
    "\t\t\tloss_eqn = Loss_criterion(xnet,tnet)\n",
    "\t\t\tloss_bc,loss_right,loss_left,loss_up = Loss_BC(x_left,t_left,V_left,x_up,t_up,V_up,x_right,t_right,V_right)\n",
    "\t\t\tloss = loss_eqn + loss_bc\n",
    "\t\t\tloss.backward()\n",
    "\t\t\t\n",
    "\t\t\toptimizer.step() \n",
    "\t\t\tpoints = torch.cat((xnet,tnet),1)\n",
    "\t\t\tU = net(points)\n",
    "\t\t\tz = U.detach().numpy()\n",
    "\n",
    "\t\t\tif epoch % 10 == 0:\n",
    "\t\t\t\tprint('\\nTrain Epoch: {} \\tLoss: {:.10f}\\tEquation Loss: {:.10f} \\t BC Loss {:.6f}\\nRight_boundary loss {:.10f}\\tLeft_boundary loss {:.10f}\\tUp_boundary loss {:.10f}\\n'.format(epoch, loss.item(),loss_eqn.item(),loss_bc.item(),loss_right.item(),loss_left.item(),loss_up.item()))\n",
    "\t\n",
    "\t\t\tif epoch % 50 == 0:\n",
    "\t\t\t\tplot_graph(z,'Predicted solution')\n",
    "\t\t\t\n",
    "\t\t\tlosses.append(loss.item())\n",
    "\n",
    "\ttoc = time.time()\n",
    "\telapseTime = toc - tic\n",
    "\tprint (\"elapse time in parallel = \", elapseTime)\n",
    "\n",
    "\tnet_in = torch.cat((xnet,tnet),1)\n",
    "\toutput = net(net_in)  #evaluate model\n",
    "\t\n",
    "\tpred = net(torch.cat((x_up, t_up), 1))\n",
    "\tV_up_pred = pred.view(len(pred), -1)\n",
    "\n",
    "\treturn output,V_up_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_num = 5\n",
    "epochs = 250\n",
    "learning_rate = 1e-3  \n",
    "\n",
    "batchsize = 128 \n",
    "batch_flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = train(device,x,t,x_bound,t_bound,v_bound,learning_rate,basis_num,epochs,batch_flag,batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = output[1].detach().numpy()\n",
    "plt.plot(arr)\n",
    "plt.plot(v_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = output[0].detach().numpy()\n",
    "plot_graph(z,\"Predicted Solution\")\n",
    "\n",
    "plot_graph(actual_soln,\"Actual Solution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(np.abs(actual_soln - z),\"Predicted Solution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
